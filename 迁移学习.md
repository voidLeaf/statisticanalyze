# 迁移学习

## 引入



## 简介



## 定义

## 分类

根据源领域和目标领域样本是否标注和任务是否相同，可以将迁移学习分为三大类：归纳迁移学习（Inductive Transfer Learning）、直推式迁移学习(Transductive Transfer Learning)、无监督迁移学习(Unsupervised Transfer Learning)。根据迁移学习所采用的技术进行划分，可以把迁移学习方法分为四种，分别是: 1)基于实例的迁移学习方法，2) 基于特征映射的迁移学习方法 3）基于参数估计的迁移学习方法 4）基于关系知识迁移的迁移学习方法。

其中，归纳式迁移学习指的是源任务和目标任务不相同但相关的迁移学习，直推式迁移学习指的是源任务和目标任务相同的迁移学习，无监督迁移学习指的是源任务和目标任务不同但相关，且源领域和目标领域都没有标签标注的迁移学习。一般来说，归纳式迁移学习中目标领域有标签标注的数据，直推式迁移学习中只有源领域有标签标注的数据，无监督的迁移学习中源领域和目标领域都没有标签标注。

在归纳式迁移学习中，如果源领域中没有标签标注，则类似于一个自学习任务，如果源领域中有标签标注，类似于多任务学习的情景。在直推式迁移学习中，如果源领域和目标领域特征空间异构，类似于领域自适应问题，如果特征空间同构则类似于样本选择偏差问题。但是与这些相关领域问题不同的是，迁移学习只着重于提升在目标领域上的学习性能。

在迁移学习技术中，基于实例的迁移学习适用于源领域和目标领域特征空间同构但数据分布不同的情况，基本思路是通过调整源领域数据的训练权值来提升学习性能，基于特征映射的迁移学习方法主要通过对源领域和目标领域的数据建立特征映射来找到共同特征，基于参数估计的迁移学习方法适用于任务不一致的情况，通常通过寻找源任务和目标任务共有的学习函数参数或假设学习函数的参数服从相同的分布来提升学习性能。基于关系知识迁移的迁移学习方法主要通过



## 归纳迁移学习

归纳迁移学习指的是源任务和目标任务不同的迁移学习，在归纳迁移学习中，通常要求目标领域中有一定的标注数据。按照

在归纳迁移学习中，基于实例的迁移学习主要应用于特征空间同构的情况。虽然源领域中的数据不能直接拿过来用于训练，但是其中的一部分对于目标任务是有价值的。Tradaboost是其中比较有代表性的方法。Tradaboost由戴文渊等人提出，是一种基于Adaboost 思想的迁移学习方法。在Tradaboost方法中，每次迭代会增加源数据中对于目标任务有帮助的“好数据”的权值，降低对目标任务没有帮助的“坏数据”的权值，最后将弱分类器累加，得到一个预测性能良好的强分类器。此外还有一些去除

根据源领域中数据是否有标注，基于特征重构的迁移学习方法可以分为有监督的特征重构和无监督的特征重构。

在有监督的特征重构方法中，Argyriou 等人提出了一个应用于多任务学习的稀疏特征学习方法。这个方法针对目标领域和源领域的数据建立一个特征映射，将高维数据映射到一个共同的低维空间，通过最小化重构之后的经验误差和参数的L2正则项来找到这个特征映射。

在无监督的特征重构方法中，Raina 等人提出了一种基于稀疏编码的方法。这个方法的基本思想分为两步：

1） 在源数据中通过求解下述优化问题找到一个基向量和基向量表达

2）基于第一步求出的基向量，通过求解优化问题找到目标数据的基向量表达

在迁移参数知识的迁移学习方法中，基本的假设是源任务和目标任务的预测函数共享一些参数或者参数服从相同的先验分布。在多任务学习中，大部分参数迁移方法都包括一个多层贝叶斯框架和一个正则化框架。迁移学习与之不同的地方在于在损失函数的选取上，多任务学习中目标任务和源任务的损失函数权重是一致的，但迁移学习中，目标任务的损失权重往往较大。其中比较有代表性的方法是Lawrence 等人提出的一种基于高斯过程的 MT-IVM 方法。在这个方法中，通过假设目标任务和源任务的参数有同样的高斯先验来学习高斯过程的参数。此外Evgeniou 等人提出了一种基于SVM框架的方法，这个方法假设每个任务中的SVM参数分为两部分，第一部分是愿任务和目标任务的公有项，第二部分是每个任务的特有项。
$$
w_s=w_0+v_s ~~~~w_T = w_0+v_T 
$$
假设对于每个任务都是求解一个分割超平面，则求解多任务SVM参数的优化问题可以表达成如下带约束的优化问题：
$$
\min_{w_0,v_t,\epsilon} J(w)
$$
其中第一项是松弛项，第二项是特有参数项的正则化项，第三项是公有参数项的正则化项。



基于关系知识的迁移



## 直推式迁移学习



## 无监督迁移学习

## 消极的迁移学习

## 应用

